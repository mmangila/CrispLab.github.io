"use strict";var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");var _regenerator = _interopRequireDefault(require("@babel/runtime/regenerator"));var _asyncToGenerator2 = _interopRequireDefault(require("@babel/runtime/helpers/asyncToGenerator")); /* eslint-disable consistent-return */
var zlib = require('zlib');var _require =
require('es6-promisify'),promisify = _require.promisify;

var gunzip = promisify(zlib.gunzip);var _require2 =

require('pako'),Z_SYNC_FLUSH = _require2.Z_SYNC_FLUSH,Inflate = _require2.Inflate;

// browserify-zlib, which is the zlib shim used by default in webpacked code,
// does not properly uncompress bgzf chunks that contain more than
// one bgzf block, so export an unzip function that uses pako directly
// if we are running in a browser.
function pakoUnzip(_x) {return _pakoUnzip.apply(this, arguments);}





























// similar to pakounzip, except it does extra counting
// to return the positions of compressed and decompressed
// data offsets
function _pakoUnzip() {_pakoUnzip = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee(inputData) {var strm, pos, i, chunks, inflator, remainingInput, _inflator, result;return _regenerator.default.wrap(function _callee$(_context) {while (1) {switch (_context.prev = _context.next) {case 0:_context.prev = 0;pos = 0;i = 0;chunks = [];case 4:remainingInput = inputData.slice(pos);inflator = new Inflate();_inflator = inflator;strm = _inflator.strm;inflator.push(remainingInput, Z_SYNC_FLUSH);if (!inflator.err) {_context.next = 11;break;}throw new Error(inflator.msg);case 11:pos += strm.next_in;chunks[i] = Buffer.from(inflator.result);i += 1;case 14:if (strm.avail_in) {_context.next = 4;break;}case 15:result = Buffer.concat(chunks);return _context.abrupt("return", result);case 19:_context.prev = 19;_context.t0 = _context["catch"](0);if (!_context.t0.message.match(/incorrect header check/)) {_context.next = 23;break;}throw new Error('problem decompressing block: incorrect gzip header check');case 23:case "end":return _context.stop();}}}, _callee, null, [[0, 19]]);}));return _pakoUnzip.apply(this, arguments);}function unzipChunk(_x2) {return _unzipChunk.apply(this, arguments);}






































// similar to unzipChunk above but slices (0,minv.dataPosition) and (maxv.dataPosition,end) off
function _unzipChunk() {_unzipChunk = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2(inputData) {var strm, cpos, dpos, blocks, cpositions, dpositions, remainingInput, inflator, _buffer, buffer;return _regenerator.default.wrap(function _callee2$(_context2) {while (1) {switch (_context2.prev = _context2.next) {case 0:_context2.prev = 0;cpos = 0;dpos = 0;blocks = [];cpositions = [];dpositions = [];case 6:remainingInput = inputData.slice(cpos);inflator = new Inflate();strm = inflator.strm; // @ts-ignore
            inflator.push(remainingInput, Z_SYNC_FLUSH);if (!inflator.err) {_context2.next = 12;break;}throw new Error(inflator.msg);case 12: // @ts-ignore
            _buffer = Buffer.from(inflator.result);blocks.push(_buffer);cpositions.push(cpos);dpositions.push(dpos);cpos += strm.next_in;dpos += _buffer.length;case 18:if (strm.avail_in) {_context2.next = 6;break;}case 19:buffer = Buffer.concat(blocks);return _context2.abrupt("return", { buffer: buffer, cpositions: cpositions, dpositions: dpositions });case 23:_context2.prev = 23;_context2.t0 = _context2["catch"](0);if (!_context2.t0.message.match(/incorrect header check/)) {_context2.next = 27;break;}throw new Error('problem decompressing block: incorrect gzip header check');case 27:case "end":return _context2.stop();}}}, _callee2, null, [[0, 23]]);}));return _unzipChunk.apply(this, arguments);}function unzipChunkSlice(_x3, _x4) {return _unzipChunkSlice.apply(this, arguments);}































































// in node, just use the native unzipping with Z_SYNC_FLUSH
function _unzipChunkSlice() {_unzipChunkSlice = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3(inputData, chunk) {var strm, cpos, dpos, decompressedBlocks, cpositions, dpositions, remainingInput, inflator, _buffer2, len, origCpos, buffer;return _regenerator.default.wrap(function _callee3$(_context3) {while (1) {switch (_context3.prev = _context3.next) {case 0:_context3.prev = 0;cpos = chunk.minv.blockPosition;dpos = chunk.minv.dataPosition;decompressedBlocks = [];cpositions = [];dpositions = [];case 6:remainingInput = inputData.slice(cpos - chunk.minv.blockPosition);inflator = new Inflate();strm = inflator.strm; // @ts-ignore
            inflator.push(remainingInput, Z_SYNC_FLUSH);if (!inflator.err) {_context3.next = 12;break;}throw new Error(inflator.msg);case 12: // @ts-ignore
            _buffer2 = Buffer.from(inflator.result);decompressedBlocks.push(_buffer2);len = _buffer2.length;cpositions.push(cpos);dpositions.push(dpos);if (decompressedBlocks.length === 1 && chunk.minv.dataPosition) {// this is the first chunk, trim it
              decompressedBlocks[0] = decompressedBlocks[0].slice(chunk.minv.dataPosition);len = decompressedBlocks[0].length;}origCpos = cpos;cpos += strm.next_in;dpos += len;if (!(origCpos >= chunk.maxv.blockPosition)) {_context3.next = 26;break;} // this is the last chunk, trim it and stop decompressing
            // note if it is the same block is minv it subtracts that already
            // trimmed part of the slice length
            decompressedBlocks[decompressedBlocks.length - 1] = decompressedBlocks[decompressedBlocks.length - 1].slice(0, chunk.maxv.blockPosition === chunk.minv.blockPosition ? chunk.maxv.dataPosition - chunk.minv.dataPosition + 1 : chunk.maxv.dataPosition + 1);cpositions.push(cpos);dpositions.push(dpos);return _context3.abrupt("break", 27);case 26:if (strm.avail_in) {_context3.next = 6;break;}case 27:buffer = Buffer.concat(decompressedBlocks);return _context3.abrupt("return", { buffer: buffer, cpositions: cpositions, dpositions: dpositions });case 31:_context3.prev = 31;_context3.t0 = _context3["catch"](0);if (!_context3.t0.message.match(/incorrect header check/)) {_context3.next = 35;break;}throw new Error('problem decompressing block: incorrect gzip header check');case 35:case "end":return _context3.stop();}}}, _callee3, null, [[0, 31]]);}));return _unzipChunkSlice.apply(this, arguments);}function nodeUnzip(input) {return gunzip(input, { finishFlush: (zlib.constants || zlib).Z_SYNC_FLUSH });}module.exports = {
  unzip: typeof __webpack_require__ === 'function' ? pakoUnzip : nodeUnzip, // eslint-disable-line
  unzipChunk: unzipChunk,
  unzipChunkSlice: unzipChunkSlice,
  nodeUnzip: nodeUnzip,
  pakoUnzip: pakoUnzip };