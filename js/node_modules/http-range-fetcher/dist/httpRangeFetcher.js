"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

var _toConsumableArray2 = _interopRequireDefault(require("@babel/runtime/helpers/toConsumableArray"));

var _regenerator = _interopRequireDefault(require("@babel/runtime/regenerator"));

var _asyncToGenerator2 = _interopRequireDefault(require("@babel/runtime/helpers/asyncToGenerator"));

var _classCallCheck2 = _interopRequireDefault(require("@babel/runtime/helpers/classCallCheck"));

var _createClass2 = _interopRequireDefault(require("@babel/runtime/helpers/createClass"));

var LRU = require('quick-lru');

var _require = require('./cacheSemantics'),
    CacheSemantics = _require.CacheSemantics;

var AggregatingFetcher = require('./aggregatingFetcher');

var crossFetchBinaryRange = require('./crossFetchBinaryRange');
/**
 * check if the given exception was caused by an operation being intentionally aborted
 * @param {Error} exception
 * @returns {boolean}
 */


function isAbortException(exception) {
  return (// DOMException
    exception.name === 'AbortError' || // standard-ish non-DOM abort exception
    // @ts-ignore
    exception.code === 'ERR_ABORTED' || // message contains aborted for bubbling through RPC
    // things we have seen that we want to catch here
    // Error: aborted
    // AbortError: aborted
    // AbortError: The user aborted a request.
    !!exception.message.match(/\b(aborted|AbortError)\b/i)
  );
} // TODO: fire events when a remote file is detected as having been changed

/**
 * smart cache that fetches chunks of remote files.
 * caches chunks in an LRU cache, and aggregates upstream fetches
 */


var HttpRangeFetcher =
/*#__PURE__*/
function () {
  /**
   * @param {object} args the arguments object
   * @param {number} [args.fetch] callback with signature `(key, start, end) => Promise({ headers, buffer })`
   * @param {number} [args.size] size in bytes of cache to keep
   * @param {number} [args.chunkSize] size in bytes of cached chunks
   * @param {number} [args.aggregationTime] time in ms over which to pool requests before dispatching them
   * @param {number} [args.minimumTTL] time in ms a non-cacheable response will be cached
   * @param {number} [args.maxFetchSize] maximum size of an aggregated request
   * @param {number} [args.maxExtraFetch] max number of additional bytes to fetch when aggregating requests
   * that don't actually overlap
   */
  function HttpRangeFetcher(_ref) {
    var _ref$fetch = _ref.fetch,
        fetch = _ref$fetch === void 0 ? crossFetchBinaryRange : _ref$fetch,
        _ref$size = _ref.size,
        size = _ref$size === void 0 ? 10000000 : _ref$size,
        _ref$chunkSize = _ref.chunkSize,
        chunkSize = _ref$chunkSize === void 0 ? 32768 : _ref$chunkSize,
        _ref$aggregationTime = _ref.aggregationTime,
        aggregationTime = _ref$aggregationTime === void 0 ? 100 : _ref$aggregationTime,
        _ref$minimumTTL = _ref.minimumTTL,
        minimumTTL = _ref$minimumTTL === void 0 ? 1000 : _ref$minimumTTL,
        _ref$maxFetchSize = _ref.maxFetchSize,
        maxFetchSize = _ref$maxFetchSize === void 0 ? chunkSize * 4 : _ref$maxFetchSize,
        _ref$maxExtraFetch = _ref.maxExtraFetch,
        maxExtraFetch = _ref$maxExtraFetch === void 0 ? chunkSize : _ref$maxExtraFetch;
    (0, _classCallCheck2.default)(this, HttpRangeFetcher);
    this.aggregator = new AggregatingFetcher({
      fetch: fetch,
      frequency: aggregationTime,
      maxFetchSize: maxFetchSize,
      maxExtraSize: maxExtraFetch
    });
    this.chunkSize = chunkSize;
    this.chunkCache = new LRU({
      maxSize: Math.floor(size / chunkSize) || 1
    });
    this.cacheSemantics = new CacheSemantics({
      minimumTTL: minimumTTL
    });
    this.stats = new LRU({
      maxSize: 20
    });
  }
  /**
   * Fetch a range of a remote resource.
   * @param {string} key the resource's unique identifier, this would usually be a URL.
   * This is passed along to the fetch callback.
   * @param {number} [position] offset in the file at which to start fetching
   * @param {number} [length] number of bytes to fetch, defaults to the remainder of the file
   * @param {object} [options] request options
   * @param {AbortSignal} [options.signal] AbortSignal object that can be used to abort the fetch
   */


  (0, _createClass2.default)(HttpRangeFetcher, [{
    key: "getRange",
    value: function () {
      var _getRange = (0, _asyncToGenerator2.default)(
      /*#__PURE__*/
      _regenerator.default.mark(function _callee(key) {
        var _this = this;

        var position,
            requestedLength,
            options,
            length,
            stat,
            firstChunk,
            lastChunk,
            fetches,
            _loop,
            chunk,
            chunkResponses,
            chunksOffset,
            _args = arguments;

        return _regenerator.default.wrap(function _callee$(_context) {
          while (1) {
            switch (_context.prev = _context.next) {
              case 0:
                position = _args.length > 1 && _args[1] !== undefined ? _args[1] : 0;
                requestedLength = _args.length > 2 ? _args[2] : undefined;
                options = _args.length > 3 && _args[3] !== undefined ? _args[3] : {};
                length = requestedLength;

                if (!(length === undefined)) {
                  _context.next = 11;
                  break;
                }

                _context.next = 7;
                return this.stat(key);

              case 7:
                stat = _context.sent;

                if (!(stat.size === undefined)) {
                  _context.next = 10;
                  break;
                }

                throw new Error("length not specified, and could not determine size of the remote file");

              case 10:
                length = stat.size - position;

              case 11:
                // calculate the list of chunks involved in this fetch
                firstChunk = Math.floor(position / this.chunkSize);
                lastChunk = Math.floor((position + length - 1) / this.chunkSize); // fetch them all as necessary

                fetches = new Array(lastChunk - firstChunk + 1);

                _loop = function _loop(chunk) {
                  fetches[chunk - firstChunk] = _this._getChunk(key, chunk, options).then(function (response) {
                    return response && {
                      headers: response.headers,
                      buffer: response.buffer,
                      chunkNumber: chunk
                    };
                  });
                };

                for (chunk = firstChunk; chunk <= lastChunk; chunk += 1) {
                  _loop(chunk);
                } // return a "composite buffer" that lets the array of chunks be accessed like a flat buffer


                _context.next = 18;
                return Promise.all(fetches);

              case 18:
                chunkResponses = _context.sent;
                chunkResponses = chunkResponses.filter(function (r) {
                  return !!r;
                }); // filter out any undefined (out of range) responses

                if (chunkResponses.length) {
                  _context.next = 22;
                  break;
                }

                return _context.abrupt("return", {
                  headers: {},
                  buffer: Buffer.allocUnsafe(0)
                });

              case 22:
                chunksOffset = position - chunkResponses[0].chunkNumber * this.chunkSize;
                return _context.abrupt("return", {
                  headers: this._makeHeaders(chunkResponses[0].headers, position, position + length - 1),
                  buffer: this._makeBuffer(chunkResponses, chunksOffset, length)
                });

              case 24:
              case "end":
                return _context.stop();
            }
          }
        }, _callee, this);
      }));

      function getRange(_x) {
        return _getRange.apply(this, arguments);
      }

      return getRange;
    }()
  }, {
    key: "_makeBuffer",
    value: function _makeBuffer(chunkResponses, chunksOffset, length) {
      if (chunkResponses.length === 1) {
        return chunkResponses[0].buffer.slice(chunksOffset, chunksOffset + length);
      } else if (chunkResponses.length === 0) {
        return Buffer.allocUnsafe(0);
      } // 2 or more buffers


      var buffers = chunkResponses.map(function (r) {
        return r.buffer;
      });
      var first = buffers.shift().slice(chunksOffset);
      var last = buffers.pop();
      var trimEnd = first.length + buffers.reduce(function (sum, buf) {
        return sum + buf.length;
      }, 0) + last.length - length;

      if (trimEnd < 0) {
        trimEnd = 0;
      }

      last = last.slice(0, last.length - trimEnd);
      return Buffer.concat([first].concat((0, _toConsumableArray2.default)(buffers), [last]));
    }
    /**
     * Fetches the first few bytes of the remote file (if necessary) and uses
     * the returned headers to populate a `fs`-like stat object.
     *
     * Currently, this attempts to set `size`, `mtime`, and `mtimeMs`, if
     * the information is available from HTTP headers.
     *
     * @param {string} key
     * @returns {Promise} for a stats object
     */

  }, {
    key: "stat",
    value: function () {
      var _stat = (0, _asyncToGenerator2.default)(
      /*#__PURE__*/
      _regenerator.default.mark(function _callee2(key) {
        var stat, chunk;
        return _regenerator.default.wrap(function _callee2$(_context2) {
          while (1) {
            switch (_context2.prev = _context2.next) {
              case 0:
                stat = this.stats.get(key);

                if (stat) {
                  _context2.next = 9;
                  break;
                }

                _context2.next = 4;
                return this._getChunk(key, 0);

              case 4:
                chunk = _context2.sent;

                this._recordStatsIfNecessary(key, chunk);

                stat = this.stats.get(key);

                if (stat) {
                  _context2.next = 9;
                  break;
                }

                throw new Error("failed to retrieve file size for ".concat(key));

              case 9:
                return _context2.abrupt("return", stat);

              case 10:
              case "end":
                return _context2.stop();
            }
          }
        }, _callee2, this);
      }));

      function stat(_x2) {
        return _stat.apply(this, arguments);
      }

      return stat;
    }()
  }, {
    key: "_headersToStats",
    value: function _headersToStats(chunkResponse) {
      var headers = chunkResponse.headers;
      var stat = {};

      if (headers['content-range']) {
        var match = headers['content-range'].match(/\d+-\d+\/(\d+)/);

        if (match) {
          stat.size = parseInt(match[1], 10);
          if (Number.isNaN(stat.size)) delete stat.size;
        }
      }

      if (headers['last-modified']) {
        stat.mtime = new Date(headers['last-modified']);
        if (stat.mtime.toString() === 'Invalid Date') delete stat.mtime;

        if (stat.mtime) {
          stat.mtimeMs = stat.mtime.getTime();
        }
      }

      return stat;
    }
  }, {
    key: "_makeHeaders",
    value: function _makeHeaders(originalHeaders, newStart, newEnd) {
      var newHeaders = Object.assign({}, originalHeaders || {});
      newHeaders['content-length'] = newEnd - newStart;
      var oldContentRange = newHeaders['content-range'] || '';
      var match = oldContentRange.match(/\d+-\d+\/(\d+)/);

      if (match) {
        newHeaders['content-range'] = "".concat(newStart, "-").concat(newEnd - 1, "/").concat(match[1]); // eslint-disable-next-line prefer-destructuring

        newHeaders['x-resource-length'] = match[1];
      }

      return newHeaders;
    }
  }, {
    key: "_getChunk",
    value: function () {
      var _getChunk2 = (0, _asyncToGenerator2.default)(
      /*#__PURE__*/
      _regenerator.default.mark(function _callee3(key, chunkNumber, requestOptions) {
        var _this2 = this;

        var chunkKey, cachedPromise, chunk, chunkAborted, fetchStart, fetchEnd, stat, alreadyRejected, freshPromise, freshChunk;
        return _regenerator.default.wrap(function _callee3$(_context3) {
          while (1) {
            switch (_context3.prev = _context3.next) {
              case 0:
                chunkKey = "".concat(key, "/").concat(chunkNumber);
                cachedPromise = this.chunkCache.get(chunkKey);

                if (!cachedPromise) {
                  _context3.next = 21;
                  break;
                }

                _context3.prev = 3;
                _context3.next = 6;
                return cachedPromise;

              case 6:
                chunk = _context3.sent;
                _context3.next = 16;
                break;

              case 9:
                _context3.prev = 9;
                _context3.t0 = _context3["catch"](3);

                if (!isAbortException(_context3.t0)) {
                  _context3.next = 15;
                  break;
                }

                // fetch was aborted
                chunkAborted = true;
                _context3.next = 16;
                break;

              case 15:
                throw _context3.t0;

              case 16:
                if (!(chunkAborted || !this.cacheSemantics.cachedChunkIsValid(chunk))) {
                  _context3.next = 19;
                  break;
                }

                this._uncacheIfSame(chunkKey, cachedPromise);

                return _context3.abrupt("return", this._getChunk(key, chunkNumber, requestOptions));

              case 19:
                // gather the stats for the file from the headers
                this._recordStatsIfNecessary(key, chunk);

                return _context3.abrupt("return", chunk);

              case 21:
                fetchStart = chunkNumber * this.chunkSize;
                fetchEnd = fetchStart + this.chunkSize; // clamp the end of the fetch to the size if we have a cached size for the file

                stat = this.stats.get(key);

                if (!(stat && stat.size)) {
                  _context3.next = 28;
                  break;
                }

                if (!(fetchStart >= stat.size)) {
                  _context3.next = 27;
                  break;
                }

                return _context3.abrupt("return", undefined);

              case 27:
                if (fetchEnd >= stat.size) fetchEnd = stat.size;

              case 28:
                alreadyRejected = false;
                freshPromise = this.aggregator.fetch(key, fetchStart, fetchEnd, requestOptions).catch(function (err) {
                  // if the request fails, remove its promise
                  // from the cache and keep the error
                  alreadyRejected = true;

                  _this2._uncacheIfSame(chunkKey, freshPromise);

                  throw err;
                });
                if (!alreadyRejected) this.chunkCache.set(chunkKey, freshPromise);
                _context3.next = 33;
                return freshPromise;

              case 33:
                freshChunk = _context3.sent;

                // gather the stats for the file from the headers
                this._recordStatsIfNecessary(key, freshChunk); // remove the promise from the cache
                // if it turns out not to be cacheable. this is
                // done after the fact because we want multiple requests
                // for the same chunk to reuse the same cached promise


                if (!this.cacheSemantics.chunkIsCacheable(freshChunk)) {
                  this._uncacheIfSame(chunkKey, freshPromise);
                }

                return _context3.abrupt("return", freshChunk);

              case 37:
              case "end":
                return _context3.stop();
            }
          }
        }, _callee3, this, [[3, 9]]);
      }));

      function _getChunk(_x3, _x4, _x5) {
        return _getChunk2.apply(this, arguments);
      }

      return _getChunk;
    }() // if the stats for a resource haven't been recorded yet, record them

  }, {
    key: "_recordStatsIfNecessary",
    value: function _recordStatsIfNecessary(key, chunk) {
      if (!this.stats.has(key)) this.stats.set(key, this._headersToStats(chunk));
    } // delete a promise from the cache if it is still in there.
    // need to check if it is still the same because it might
    // have been overwritten sometime while the promise was in flight

  }, {
    key: "_uncacheIfSame",
    value: function _uncacheIfSame(key, cachedPromise) {
      if (this.chunkCache.get(key) === cachedPromise) {
        this.chunkCache.delete(key);
      }
    }
    /**
     * Throw away all cached data, resetting the cache.
     */

  }, {
    key: "reset",
    value: function reset() {
      this.stats.clear();
      this.chunkCache.clear();
    }
  }]);
  return HttpRangeFetcher;
}();

module.exports = HttpRangeFetcher;